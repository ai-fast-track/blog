{
  
    
        "post0": {
            "title": "Time Series Classification Using Deep Learning - Part 1",
            "content": ". In this article, I will introduce you to a new package called timeseries for fastai2 that I lately developed. The timeseries package allows you to train a Neural Network (NN) model in order to classify both univariate and multivariate time series using the powerful fastai2 library and achieve State Of The Art (SOTA) results. . . Note: The timeseries package is still under development, and it is not part of the official fastai2 library. . Objectives: . The key objectives of this series of articles are: . Introduce you to time series classification using Deep Learning, . | Show you a step by step how this package was built using fastai2 library, . | Introduce you to some key concepts of the fastai2 library such as Datasets, DataLoaders, DataBlock, Transform, etc. . | Introduction . Unlike Computer Vision (CV), Time Series (TS) analysis is not the hottest topic in the Artificial Intelligence (AI)/DL eco-system. Lately, CV starts to lose a bit of its luster because of the amount of controversies around facial detection abusive applications among other reasons. As a potential positive consequence, we hope more attention will be geared towards TS analysis opening the door to more innovation in the TS field. . Another positive aspect of using DL in the TS field is the fact that training a NN TS model uses far less both CPU and GPU resources. As a matter of fact, it uses a fraction of the compute resources in comparison to those needed to train NN models in both CV and NLP. . Compared to both CV and Natural Language Processing (NLP), TS is still in its infancy in terms of DL innovations. This offers the opportunity to talented people to step in this domain and to start innovating and creating new models that are specifically designed to time series. Those new models could be built from the ground or inspired by some well established NN models such as ResNet in CV, and LSTM in NLP. . fastai2 could play a significant role in developing this field thanks to its unified APIs that already spans several domains such as Vison, NLP, and Tabular, on one hand, and to its level of granularity in terms of APIs depth (High, Mid, and Low Levels APIs), on the other hand. . By using fastai2, not only, this will accelerate the development of new libraries but it will also offer a fast learning curve for users exploring those new TS libraries: in other word, we can leverage the transfer learning between different modules that constitutes the fastai2 library. . Before diving in the core subject, let&#39;s define what a time series is. . Time Series Short Introduction . A time series is a simple set of data point stored in a chronological order (time stamps). Time series can be found in virtually all domains and can be divided into 2 types: . • Univariate time series: Representing a single wave. The example, here below, shows an ECG recording extracted from the ECG200 dataset. An analysis using that dataset is shown in the End-to-End Training section. . . • Multivariate time series: Representing a set of related waves such as NATOPS recording which represent sensors recordings at different locations: hands, elbows, wrists and thumbs. For more details, check out the Toy Data section here below. . . . Time Series Analysis . Time series analysis is becoming increasingly important because of the easy access and the wide spread of time series generation tool such as mobile devices, internet of things, logging and monitoring data generated in virtually all the industries, etc. What will become even more crucial is the design of end-to-end tools capable of analyzing such a gigantic amount of data. Deep Learning will play a key role in providing such tools. . Time series analysis aims to extract meaningful information that allow the user to get actionable insights. It can be divided into 3 main categories: . Time Series Classification (TSC): We present a time series to a Neural Network (NN) model, and the latter predicts its label (class). This article will focus on this category | Time Series Regression (TSR): This is quite similar to TSC, and share the same data processing. It can be seen as TSC special case where the number of labels (classes) is reduced to 1, and represented by a float instead of an integer (category) | Time Series Forecasting (TSF): it consists in predicting the future values (or range of values) of a time series (e.g. temperature, sales, stock price, etc.) based on previously observed values | The timeseries package presented in this article covers both time series classification and regression. . . Note: AIoT and AI in EdgepointMany big companies and startups are heavily investing in developing both AI-enabled processors and micro-controllers for AI in edgepoint Applications.Nowadays, the edge AI portion of a smartphone System-on-Chip (SoC) represents only about 5% of the total area and about US$3.50 of the total cost, and would use about 95% less power than the whole SoC does. This stressed out how affordable the AI chips already are.The wide spread of both AI chips and artificial intelligence of things (AIoT) will make NN model training and/or inference at edgepoints a reality. AI inference on the edgepoint device is very attractive because it decreases latency, saves bandwidth, helps privacy, and saves power associated with RF transmission of data to the cloud.Furthermore, the ability to collect, interpret, and immediately act on vast amounts of data is critical for many of the data-heavy applications.As a consequence, this will likely drive significant changes for consumers and enterprises applications. Smart machines powered by AI chips will have a huge impact on a wide variety of industries such as manufacturing, logistics, agriculture, energy, etc.TS processing using AI/DL techniques could play a key role in implementing AI in edgepoint given the fact that TS uses far less resources such as memory and compute than both CV and NLP counterparts. . Toy Data . As an illustration, I will use a multivariate time series from Naval Air Training and Operating Procedures Standardization (NATOPS) dataset. The data is generated by sensors on the hands, elbows, wrists and thumbs (see figure here above). The data are the x, y, z coordinates for each of the 8 locations. For each sensor and each axis, we have a time series that represent the value of x (respectively y, and z) during the execution of a command. For instance, channel 3 (ch3) on the graph, here above, shows the Hand tip right X coordinate at different timestamps. For each gesture, we will have 24 curves corresponding to 8 sensors x 3 coordinates. The whole represents a multivariate time series. . Classes (Labels) . The dataset contains six classes representing 6 separate actions, with the following meaning: 1: I have command 2: All clear 3: Not clear 4: Spread wings 5: Fold wings 6: Lock wings . What is the goal of the NATOPS time series classification? . The NATOPS dataset contains time series recordings corresponding to different commands executed by different operators. . The goal is to train our NN model using both a training dataset and a valid dataset. After training our model and achieving a high accuracy score, we feed our model a given sensor test data without providing its class (label) (e.g. &quot;4: Spread wings&quot;), and our model will predict which class the sensor data correspond to (hopefully &quot;4: Spread wings&quot;). . End-to-End Training . In this section, I will show how easy to train a NN model, and achieve some SOTA results in a record time. Before doing that, let’s introduce the timeseries package. The latter was designed to mimic the unified fastai v2 APIs used for vision, text, and tabular in order to ease its use among users familiar with the fastai2 APIs. As a consequence, those who already used fastai2 vision module will feel familiar with the timeseries APIs. Timeseries package uses Datasets, DataBlock, and a new TSDataLoaders and a new TensorTS classes. It has the following mapping with fastai2 vision module: . TensorImage &lt;&gt; TensorTS Conv2D &lt;&gt; Conv1D . The timeseries package also references 128 Univariate and 30 Multivariate time series datasets. Using URLs_TS class (similar to fastai URLs class) you might play with one of those 158 datasets. . Similarly to fastai vision examples, we can train any time series dataset end-to-end with 4 lines of code. In the example shown, here below, we use TSDataLoaders and the multivariate NATOPS dataset. . . Tip: The whole training_using_default_settings.ipynb notebook can be run in Google Colab by clicking on the link. . path = unzip_data(URLs_TS.NATOPS) dls = TSDataLoaders.from_files(bs=32,fnames=[path/&#39;NATOPS_TRAIN.arff&#39;, path/&#39;NATOPS_TEST.arff&#39;], batch_tfms=[Normalize()]) learn = ts_learner(dls) learn.fit_one_cycle(25, lr_max=1e-3) . Using a SOTA NN model called InceptionTime (published in September 2019), and the default fastai2 settings, we can achieve around 98,5% accuracy in only 20 epochs. The following figure shows some of the predictions results (Predicted/True classes): . . The package also features Class Activation Map (CAM) for time series. CAM is used to help interpreting the results of our NN model decision. The package offers both CAM and GRAD-CAM as well as user-defined CAM. The cam_tutorial_ECG200.ipynb notebook illustrates a simple example of the univariate ECG200 dataset classification task (Normal Heartbeat vs. Myocardial Infarction). Like in vision, the colors represent the activation values at a given layer (in this example it is located before the FC layer (last layer)). Notice how the Myocardial Infarction plots (2nd, 3rd, and 4th) share similar activation zones that are quite different from those corresponding to Normal Heartbeat plots (1st and 5th). This kind of representation eases the interpretation of the results obtained using a given NN model (InceptionTime, in this case). . . Tip: the cam_tutorial_ECG200.ipynb notebook can be run in Google Colab by clicking on the link. . . Code Walk Through . let’s decipher, line by line, the 4 lines of code shown here above: . Line 1: Downloading Data . path = unzip_data(URLs_TS.NATOPS) . Downloading a dataset (NATOPS dataset precisely) hosted at the Time Series Classification Repository website, unzipping the dataset, and saving it a separate folder under the local ./fastai/data folder. . | Line 2: Creating Datasets and DataLoaders Objects . dls = TSDataLoaders.from_files(bs=32,fnames=[path/&#39;NATOPS_TRAIN.arff&#39;, path/&#39;NATOPS_TEST.arff&#39;], batch_tfms=[Normalize()]) . Creating a 2 Dataset objects containing a train dataset, and a valid dataset. . | Creating 2 DataLoader objects that allows us to create mini-batches for both training and valid datasets. . | . | Line 3: Creating a Learner Object . learn = ts_learner(dls) . We create a learner where we basically do the following: . Create an NN model, InceptionTime in our case. . | Create a Learner object using some state-of-the-art techniques found in the fastai2 library such as the Ranger optimizer, callbacks, etc. . | . | Line 4: Training Model . learn.fit_one_cycle(25, lr_max=1e-3) . We train our model using one the fastai magic ingredient being the fast converging training algorithm called fit_one_cycle(). Running the last line, we achieve accuracy higher than 98% in less than 20 epochs. . | Admittedly, the 4 lines shown here above can be a bit cryptic for someone how is new to the fastai2 library. Those lines show how to train a model using the fastai2 high level API. At that level, many settings are set by default in order to avoid overwhelming new users by exposing too many parameters that are difficult to grasp at the beginning of their learning journey. As shown here above, using fastai2 default settings we are very often capable of reaching SOTA results in fewer epochs. . As a very versatile API covering a large range of use-cases, fastai2 offers 3 levels of APIs: High level, Mid Level, and Low Level. Depending on both use-cases and user&#39;s fastai2 proficiency, one might choose one or the other level. . In the next article, I will take that opportunity to start building the timeseries module using the Mid Level APIs. I chose that level because both fastai version 1 and/or Pytorch users will feel in familiar territories. We will leverage the new fastai2 Datasets and DataLoaders classes, and show how both versatile and powerful are. . Conclusion . I hope this first article convey you into trying the timeseries package. You might also check out its documentation. All the notebooks are self-contained, and documented. You will be able to directly run them in Google Colab. . If you give it a try and found it interesting/helpful, please let others know it by staring it on GitHub, and share it with your friends and colleagues who might be interested in this topic. . As a new Twitter user, I would like to kindly ask you to follow me @ai_fast_track. I will post there the sequel of this blog post. . I also intend to post on Twitter, on regular basis, Tips &amp; Tricks about fastai(2) and Deep Learning in general. Stay Tuned, and Stay Safe! . Note: I wanted to end this article by saying that I was immune to &quot;unfollowers&quot; because I haven&#8217;t any follower yet. To my big surprise, I discovered that I already had one follower: @jcatanza, before even starting tweeting. Thank you Joseph for being my first follower! Hopefully, other fastai members will do the same! . .",
            "url": "http://ai-fast-track.com/timeseries/2020/05/21/time-series-using-deep-learning-part-1.html",
            "relUrl": "/timeseries/2020/05/21/time-series-using-deep-learning-part-1.html",
            "date": " • May 21, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "3 ways to pip install a package - fastai2 use-case",
            "content": "Introduction . In this article, I will show 3 methods to install the new fastai2 library using pip install. The 3 methods described here can be used to similar python libraries published on both pypi repository and on GitHub. I voluntarily omitted the conda install option because I wanted to focus on the methods that can be reproduced in any free cloud environment such as Google Colab or Kaggle. . . Note: In this article, the different methods described are generic and therefore can be applied to any python package. You only have to replace the name fastai2 by the name of the corresponding python package such as torch . 1- Installing from pypi repository . . Note: The first method is the most common way to install a stable version of a python package. It will be the recommeded one once fastai2 will be officially released. . Although, fastai2 is still under development and its official release is expected to be during the next summer, it is important to be familiar with this first method especially if you intend to use fastai2 in a production environment. . To install fastai2 from fastai2 pypi repository, type the following command either from: . the terminal: . pip install fastai2 . | or from a Jupyter notebook cell: . !pip install fastai2 . | The difference between the 2 options is the use of the ! in the case of Jupyter notebook. However, the result is the same, the fastai2 package will be installed in the current active virtual environment. . . Important: Following the best practices, it is important to create and activate a virtual environment before installing any python package. Lacking to do so, the package will be installed in your current virtual environment. This means that most likely, it will be installed in the base virtual environment in Ananconda (base is the default virual environment created when you installed Anaconda). Check out the Appendices A and B, here below, on how to respectively install and create a virtual environment. . . Tip: You can create several virtual environments on the same machine. The following is the output of the different virtual environments that I created on my local machine. . Running the following command: . conda env list . outputs the list of my current virtual environments: . # conda environments: # base /home/farid/anaconda3 fastai2 /home/farid/anaconda3/envs/fastai2 fastai2_dev * /home/farid/anaconda3/envs/fastai2_dev fastai /home/farid/anaconda3/envs/fastai gluon /home/farid/anaconda3/envs/gluon prophet /home/farid/anaconda3/envs/prophet . The asterisk (*) indicates the active virtual environment . To check where the fastai2 package has been install, run the following command: . pip show fastai2 . This command displays the following useful information: . Name: fastai2 Version: 0.0.11 Summary: Version 2 of the fastai library Home-page: https://github.com/fastai/fastai2 Author: Jeremy Howard, Sylvain Gugger, and contributors Author-email: info@fast.ai License: Apache Software License 2.0 Location: /home/farid/anaconda3/envs/fastai2/lib/python3.6/site-packages Requires: scikit-learn, pandas, fastprogress, requests, scipy, pillow, torchvision, matplotlib, pyyaml, spacy, torch, fastcore Required-by: . It displays the package name, the version number, the location where it was installed (with the name of the virtual environment: in our case it is fastai2), and some other information. . Note: At the present time (March 17th, 2020), the fastai version found on the pypi repository is 0.0.11 . 2- Installing from GitHub - Non-editable package . . Note: This method is used by users who are interested in the latest and the greatest features found in the fastai2 Github repository. In general, those users are interested in using the latest fastai2 package without the intention to either contibute to the fastai2 project or build new modules that can be used as fastai2 extensions. If this sound a bit unclear, everything will be crystal clear once you have read the Method 3 section. . The second method consists in installing the fastai2 package from the fastai2 GitHub repository. This begs the question: Why would we be interested in doing so? The answer is simple: If a python package is under development, and changes in the source code are introduced on a regular basis, chances are the package found on the pypi repository is lagging behind. In order to use the latest fastai2 features you need to install fastai2 from its GitHub repository. . As illustration of a situation where this option is convenient, I will cite the example where Jeremy shared a Kaggle kernel in which he wanted to show how to use a new developed module called medical. The latter was under development, and was not available on the pypi repository. Therefore the solution was to install the latest fastai2 version (that includes the medical module) by running the following command either on: . the terminal: . pip install git+https://github.com/fastai/fastai2.git . | or from a Jupyter notebook cell: . !pip install git+https://github.com/fastai/fastai2.git . | By comaparing the command above with the one used in method 1, you might have noticed that we replaced fastai2 by git+https://github.com/fastai/fastai2.git: this means that we are directly installing the latest source code found in the fastai2 GitHub repository. . Important: When using this option, it is very important to also install the fastcore library using the very same method: . The command shown, here below, should be run after installing the fastai2 package from its repository in order to align the 2 versions: . either from terminal: . pip install git+https://github.com/fastai/fastcore.git . and from a Jupyter notebook cell: . !pip install git+https://github.com/fastai/fastcore.git . You may ask yourself why do we have to also install the fastcore library from GitHub given the fact that fastai2 will always install fastcore because it is part of its requirements. The answer relies on fact that fastai2 will install the latest version found in the pypi repository as opposed to the latest version found on GitHub. If the fastai2 GitHub version is using new features found in the fastcore latest GitHub version, it will lead to an incompatibility if we use fastai2 latest GitHub version combined with the fastcore pypi version: basically, if we had done so we would have been mixing 2 misaligned versions. Consequently, we will end up experiencing some issues, and some errors will ultimately surface. Therefore, it is better to follow the good practice by pip installing both of them using the method described here above. . 3- Installing from GitHub- Editable package . . Note: This method is used by developers who are usually either 1) actively contributing to fastai2 project by adding new features or fixing bugs, or 2) creating their own modules, and making sure that their source code stay in sync with the fastai2 latest version. Lacking to do so, they will ultimately realize that their code is incompatible with the fastai2 repository one. . The goal is to keep our library (that depends on fastai2) aligned to the fastai2 one hand, and to avoid to keep pip installing both fastai2 and fastcore every time a new version is released (this would have been the case had we used Method 2). Thankfully, there exists a magic method (Method 3) that consists in using a so-called an editable version of the target python package (i.e. fastai2 and fastcore) . Installing an editable version of fastai2 is pretty straightforward. All we have to do is to follow these 3 simple steps by running the following commands from a terminal console: . git clone https://github.com/fastai/fastai2 cd fastai2 pip install -e . . Basically, we are cloning the fastai2 repository, then hopping into the cloned fastai2 folder, and finally running the command to pip install the package (fastai2) from the current folder (hence the use of the dot .) as an editable version by using the -e switch. . We also have to follow the same steps for the fastcore library: . git clone https://github.com/fastai/fastcore cd fastcore pip install -e . . For those following along, and who are familiar with this option, they might notice there is a tiny discrepancy between this method and the one found on the fastai2 repository (shown here below): . git clone https://github.com/fastai/fastai2 cd fastai2 pip install -e &quot;.[dev]&quot; . The difference is the use of the [dev] part. Using the [dev] flag issue an order to the installer to pip install all the packages listed under the dev requirements (dev_requirements = nbdev). This means the nbdev package (its a fastai package) will be installed from the pypi repository. Given the fact that nbdev is also under development, we may experienced some issues caused by a misalignment between the 3 different fastai packages being fastai2, fastcore, and nbdev. For that reason, it is desirable to also install the nbdev package as an editable package as follow: . git clone https://github.com/fastai/nbdev cd nbdev pip install -e . . Now that we installed our editable package, how are we going to update it? The answer is very simple: we git pull our latest version from the corresponding GitHub repository. Therefore, for the fastai2 package, we just have to hop into its cloned forder and run the following command: . git pull . This command will both update our cloned version of the fastai2 repository and update our editable package had its version changed. We have to run the command, here above, for both fastai2 and fastcore. . Appendix A: How to install Anaconda . On linux . $ curl -O https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh $ sha256sum Anaconda3-2019.10-Linux-x86_64.sh 46d762284d252e51cd58a8ca6c8adc9da2eadc82c342927b2f66ed011d1d8b53 Anaconda3-2019.10-Linux-x86_64.sh $ bash Anaconda3-2019.10-Linux-x86_64.sh $ source ~/.bashrc . . Warning: Please replace the Anaconda3-2019.10-Linux-x86_64.sh by a more recent filename found in the [Anaconda installer archive] (https://repo.continuum.io/archive/) . . On Windows . Download the Anaconda Windows installer | Select Python 3.6 or higher | Run the installer, and follow the instructions | . Appendix B: Creating a conda enviroment . On either Linux and Windows run the following commands: . conda create -n fastai2 python=3.6 anaconda conda activate fastai2 . . Tip: You can choose which version of python you would like to install. In the case here above, the version 3.6 will be installed. . Appendix C: Useful pip commands . Install a python package (e.g. fastai2) from the pypi repository: | . pip install fastai2 . Uninstall a python package (e.g. fastai2): | . pip uninstall fastai2 . Show some information about a package (e.g. fastai2) | . pip show fastai2 . This is what it displayed on my local machine, at the moment I published the present post: . Name: fastai2 Version: 0.0.11 Summary: Version 2 of the fastai library Home-page: https://github.com/fastai/fastai2 Author: Jeremy Howard, Sylvain Gugger, and contributors Author-email: info@fast.ai License: Apache Software License 2.0 Location: /home/farid/anaconda3/envs/fastai2/lib/python3.6/site-packages Requires: scikit-learn, pandas, fastprogress, requests, scipy, pillow, torchvision, matplotlib, pyyaml, spacy, torch, fastcore Required-by: . Appendix D: Useful conda commands . Create a conda virtual environment called fastai2 with python 3.6 version | . conda create -n fastai2 python=3.6 anaconda . Activate a conda virtual environment called fastai2 | . conda activate fastai2 . List all the conda virtual environments | . conda env list . Install a python package (e.g. torch) from the conda repository: | . conda install torch -c torch . -c : indicate which channel to use to install the corresponding package . Uninstall a python package (e.g. torch): | . conda uninstall torch . List all the packages installed in the current conda virtual environment | . conda list . List all the packages installed that start with the prefix fast in the current conda virtual environment | . conda list fast . Output on my machine indicating the package name, current installed version, and the channel: . # Name Version Build Channel fastai2 0.0.12 dev_0 &lt;develop&gt; fastcache 1.1.0 py36h7b6447c_0 fastcore 0.1.15 dev_0 &lt;develop&gt; fastprogress 0.2.2 pypi_0 pypi fastscript 0.1.4 pypi_0 pypi . . Note: You might have noticed that both my fastai2 and fastcore package share the same Build Channel name being dev_0: this indicates that they both are editable versions. . Conclusion . In this article, I presented an overview describing 3 methods to install any package published on both pypi repository and GitHub. I used fastai2 library as use-case. However, the methods described here can be applied to any other package: the name fastai2 can be replaced by the corresponding package name such as torch. I also explained the goal of each of these 3 methods, and which method to pick depending on your specific use-case. .",
            "url": "http://ai-fast-track.com/python/2020/03/17/how-to-pip-install-package.html",
            "relUrl": "/python/2020/03/17/how-to-pip-install-package.html",
            "date": " • Mar 17, 2020"
        }
        
    
  

  
  
      ,"page0": {
          "title": "",
          "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
          "url": "http://ai-fast-track.com/archives/2020-01-14-test-markdown-post.html",
          "relUrl": "/archives/2020-01-14-test-markdown-post.html",
          "date": ""
      }
      
  

  

  
      ,"page2": {
          "title": "About Me",
          "content": "Pasionate about AI / Deep Learning, and their applications for good. | Helping democratizing AI / Deep Learning | Happy to share all what I learned with all people no matter their background | Hanging around at the most open and most welcoming deep learning community: fastai | Trying to contribute to fastai community as much as I can: Learning with them and giving back. | Presently working in developing the timeseries package: a time series analysis package using deep learning for fastai2 library | . Background . BSc in Physics | MSc in Biomedical Engineering | PhD in Biomedical Engineering | Postdoc in both Biomedical Engineering and Neurosciences | Creator of StatMap3D software : Statitical Brain Electrical Mapping Software | Creator of DataFinder : Multidisciplinary Clinical and Research Database | Previously Java Certified Trainer when Java was a thing | . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "http://ai-fast-track.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}